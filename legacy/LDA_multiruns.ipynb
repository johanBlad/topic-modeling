{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for importing modules from a sub-directory\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    print(\"CHANGE DIR TO ROOT\")\n",
    "    os.chdir(r\"../\")\n",
    "    \n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import nltk\n",
    "from preprocess import build_ne_gold_phraser, get_gold_ngrams, apply_ngrams\n",
    "import gensim\n",
    "from evaluation import get_median ,get_bot, get_top\n",
    "from gensim import matutils, models, corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print topics with N top words\n",
    "def print_topics_words(model, num_topics):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 10);\n",
    "        word_dict['T#' + '{:02d}'.format(i)] = [i[0] for i in words];\n",
    "        df = pd.DataFrame(word_dict);\n",
    "        df.to_csv(f'DN_mallet_{num_topics}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting topic terms to be used for calcualtion of coherence\n",
    "def get_lda_topics(model, num_topics):\n",
    "    word_dict = [];\n",
    "    for i in range(num_topics):\n",
    "        wp = model.show_topic(i, topn=10)\n",
    "        key_words = [topic[0] for topic in wp] \n",
    "        word_dict.append(key_words)\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate document-topic relative sparseness\n",
    "def doc_top_relative_sparseness(mod_type, model, corpus, top_n):\n",
    "    \n",
    "    if mod_type == 'gensim':\n",
    "        doc_topics = model.get_document_topics(corpus, per_word_topics=False, minimum_probability=0.0)\n",
    "        res = []\n",
    "        for k, doc in enumerate(doc_topics):\n",
    "            topics = sorted([topic[1] for topic in doc], reverse=True)\n",
    "            res.append(sum(topics[:top_n])/sum(topics))\n",
    "        return res\n",
    "        \n",
    "    else:\n",
    "        fname = model.fdoctopics()\n",
    "        doc_topics = model.read_doctopics(fname, eps=0, renorm=False)\n",
    "        res = []\n",
    "    \n",
    "        for k, doc in enumerate(doc_topics):\n",
    "            topics = sorted([topic[1] for topic in doc], reverse=True)\n",
    "            res.append(sum(topics[:top_n])/sum(topics))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mallet path\n",
    "mallet_path ='mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n):\n",
    "    \n",
    "    if mod_type == 'gensim':\n",
    "        #LDA implemented with gensim\n",
    "        model = gensim.models.LdaModel(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=k,\n",
    "                                       alpha=alpha,\n",
    "                                       eta=eta,\n",
    "                                       passes=3,\n",
    "                                       iterations=100)\n",
    "    else:\n",
    "        #LDA implemented with mallet\n",
    "        model = models.wrappers.LdaMallet(mallet_path,\n",
    "                                          corpus=corpus,\n",
    "                                          id2word=id2word,\n",
    "                                          num_topics=k)\n",
    "    \n",
    "    print_topics_words(model, k)\n",
    "    topics = get_lda_topics(model, k)\n",
    "    flat_topic_terms = [term for topic in topics for term in topic]\n",
    "    topic_terms_not_in_ext_corpus = [[term] for term in flat_topic_terms if term not in tok2id]\n",
    "    \n",
    "    missing_topics = len(topic_terms_not_in_ext_corpus)\n",
    "    print(f'{missing_topics} number of terms not in extrinsic corpus added as separate one-term documents')\n",
    "    \n",
    "    smooth_corpus = extrinsic_data + topic_terms_not_in_ext_corpus\n",
    "    smooth_gensim_dict = corpora.Dictionary(smooth_corpus)\n",
    "    \n",
    "    #Calculate coherence\n",
    "    cv = CoherenceModel(topics=topics,\n",
    "                        texts=smooth_corpus,\n",
    "                        dictionary=smooth_gensim_dict,\n",
    "                        topn=ntw,\n",
    "                        coherence='c_v')\n",
    "    umass = CoherenceModel(topics=topics,\n",
    "                           texts=data,\n",
    "                           dictionary=id2word,\n",
    "                           topn=ntw,\n",
    "                           coherence='u_mass')\n",
    "    \n",
    "    #Calculate relative sparseness\n",
    "    res = doc_top_relative_sparseness(mod_type, model, corpus, top_n)\n",
    "\n",
    "    return model, cv.get_coherence_per_topic(), umass.get_coherence_per_topic(), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coherence_values(mod_type, corpus, id2word, data, s, topics_range, alpha, eta, ntw, top_n, n_grams):\n",
    "    \n",
    "    pbar = tqdm.tqdm(total=len(topics_range))\n",
    "    \n",
    "    model_results = {'Date': [],\n",
    "                     'Model': [],\n",
    "                     '#articles': [],\n",
    "                     '#topics': [],\n",
    "                     'time (s)': [],\n",
    "                     'n_grams': [],\n",
    "                     'cv_avg': [],\n",
    "                     'cv_top': [],\n",
    "                     'cv_bot': [],\n",
    "                     'umass_avg': [],\n",
    "                     'umass_top': [],\n",
    "                     'umass_bot': [],\n",
    "                     'rs_avg': [],\n",
    "                     'rs_top': [],\n",
    "                     'rs_bot': [],\n",
    "                     }\n",
    "    \n",
    "    if 1 == 1:\n",
    "        for k in topics_range:\n",
    "            # get the coherence score for the given parameters\n",
    "            t0 = time.time()\n",
    "            model, cv, umass, res = compute_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n)\n",
    "            \n",
    "            # calculate runtime\n",
    "            t1 = time.time()\n",
    "            runtime = round((t1-t0), 1)\n",
    "            \n",
    "            # get current date and time\n",
    "            now = datetime.now()\n",
    "            date = now.strftime(\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "            # calculate cv metrics\n",
    "            m_cv = sorted(cv)\n",
    "            cv_avg = round(np.mean(m_cv), 3)\n",
    "            cv_top = get_top(m_cv)\n",
    "            cv_bot = get_bot(m_cv)\n",
    "            \n",
    "            # calculate umass metrics\n",
    "            m_umass = sorted(umass)\n",
    "            umass_avg = round(np.mean(m_umass), 3)\n",
    "            umass_top = get_top(m_umass)\n",
    "            umass_bot = get_bot(m_umass)\n",
    "            \n",
    "            # calculate rs metrics\n",
    "            m_rs = sorted(res)\n",
    "            rs_avg = round(np.mean(m_rs), 3)\n",
    "            rs_top = get_top(m_rs)\n",
    "            rs_bot = get_bot(m_rs)\n",
    "        \n",
    "            # Save the model results\n",
    "            model_results['Date'].append(date)\n",
    "            model_results['Model'].append(mod_type)\n",
    "            model_results['#articles'].append(s)\n",
    "            model_results['#topics'].append(k)\n",
    "            model_results['time (s)'].append(runtime)\n",
    "            model_results['n_grams'].append(n_grams)\n",
    "            model_results['cv_avg'].append(cv_avg)\n",
    "            model_results['cv_top'].append(cv_top)\n",
    "            model_results['cv_bot'].append(cv_bot)\n",
    "            model_results['umass_avg'].append(umass_avg)\n",
    "            model_results['umass_top'].append(umass_top)\n",
    "            model_results['umass_bot'].append(umass_bot)\n",
    "            model_results['rs_avg'].append(rs_avg)\n",
    "            model_results['rs_top'].append(rs_top)\n",
    "            model_results['rs_bot'].append(rs_bot)\n",
    "            pbar.update(1)\n",
    "\n",
    "        pd.DataFrame(model_results).to_csv('DN_mallet_results.csv', index=False)\n",
    "        #pd.DataFrame(model_results).to_csv('DN_gensim_results.csv', index=False, mode='a', header=False)\n",
    "        pbar.close()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################   TEST PARAMETERS  ###################################################\n",
    "\n",
    "DATASET_TYPE = 'DN'\n",
    "DATASET_SIZE = '10000'\n",
    "DATASET_INDEX = '1'\n",
    "\n",
    "# Load pickles:\n",
    "c1 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_1.pkl', 'rb'))\n",
    "c2 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_2.pkl', 'rb'))\n",
    "c3 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_3.pkl', 'rb'))\n",
    "c4 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_4.pkl', 'rb'))\n",
    "c5 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_5.pkl', 'rb'))\n",
    "extrinsic_data = pickle.load( open(\"pickles/efselab_extrinsic_20000.pkl\",\"rb\"))\n",
    "data = c1 + c2 + c3 + c4 + c5\n",
    "\n",
    "# Use n_grams or not\n",
    "n_grams = False\n",
    "\n",
    "\n",
    "# Use NNGRAM is true, apply on data and extrinsic data\n",
    "if (n_grams is True):\n",
    "    NE_GRAMS_FILE = f'ngrams_per_dataset/ne_ngrams_{DATASET_TYPE}_{DATASET_SIZE}_{DATASET_INDEX}.pkl'\n",
    "    ne_ngrams = pickle.load(open(NE_GRAMS_FILE, 'rb'))\n",
    "    gold_ngrams = get_gold_ngrams()\n",
    "\n",
    "    # Optimized pipeline for applying ne+gold ngrams to a corpus (with ne and gold pickles)\n",
    "    phraser = build_ne_gold_phraser(ne_ngrams, gold_ngrams)\n",
    "    data = apply_ngrams(data, phraser)\n",
    "    \n",
    "    # ngram on extrinsic\n",
    "    extrinsic_data = apply_ngrams(extrinsic_data, phraser)\n",
    "    \n",
    "    \n",
    "# Format Gensim components for data\n",
    "s = len(data)\n",
    "id2word = corpora.Dictionary(data)\n",
    "id2word.filter_extremes(no_below=2)\n",
    "corpus = [id2word.doc2bow(text) for text in data]\n",
    "\n",
    "# Format Gensim components for extrisnic data\n",
    "extrinsic_id2word = corpora.Dictionary(extrinsic_data)\n",
    "extrinsic_corpus = [extrinsic_id2word.doc2bow(text) for text in extrinsic_data]\n",
    "\n",
    "# Format Gensim components for Coherence metrics\n",
    "ext_gensim_dict = corpora.Dictionary(extrinsic_data)\n",
    "tok2id = ext_gensim_dict.token2id\n",
    "\n",
    "# Model type, mallet och gensim\n",
    "mod_type = 'mallet'\n",
    "\n",
    "# Topics range\n",
    "min_topics = 10\n",
    "max_topics = 151\n",
    "step_size = 10\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = 'auto' # Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "\n",
    "# Beta parameter\n",
    "eta = 'auto' # Dirichlet hyperparameter eta: Word-Topic Density\n",
    "\n",
    "# Number of topwords used to compute coherence\n",
    "ntw = 10\n",
    "\n",
    "# Number of topic used for calculation of matrix spareness\n",
    "top_n = 1\n",
    "\n",
    "model = print_coherence_values(mod_type, corpus, id2word, data, s, topics_range, alpha, eta, ntw, top_n, n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
