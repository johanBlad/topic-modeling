{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary for importing modules from a sub-directory\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if os.getcwd().split('/')[-1] == 'notebooks':\n",
    "    print(\"CHANGE DIR TO ROOT\")\n",
    "    os.chdir(r\"../\")\n",
    "    \n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import nltk\n",
    "from preprocess import build_ne_gold_phraser, get_gold_ngrams, apply_ngrams\n",
    "import gensim\n",
    "from evaluation import get_median ,get_bot, get_top\n",
    "from gensim import matutils, models, corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting topic terms to be used for calcualtion of coherence\n",
    "def get_lda_topics(model, num_topics):\n",
    "    word_dict = [];\n",
    "    for i in range(num_topics):\n",
    "        wp = model.show_topic(i, topn=10)\n",
    "        key_words = [topic[0] for topic in wp] \n",
    "        word_dict.append(key_words)\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate document-topic relative sparseness\n",
    "def doc_top_relative_sparseness(mod_type, model, corpus, top_n):\n",
    "    \n",
    "    if mod_type == 'gensim':\n",
    "        doc_topics = model.get_document_topics(corpus, per_word_topics=False, minimum_probability=0.0)\n",
    "        res = []\n",
    "        for k, doc in enumerate(doc_topics):\n",
    "            topics = sorted([topic[1] for topic in doc], reverse=True)\n",
    "            res.append(sum(topics[:top_n])/sum(topics))\n",
    "        return res\n",
    "        \n",
    "    else:\n",
    "        fname = model.fdoctopics()\n",
    "        doc_topics = model.read_doctopics(fname, eps=0, renorm=False)\n",
    "        res = []\n",
    "    \n",
    "        for k, doc in enumerate(doc_topics):\n",
    "            topics = sorted([topic[1] for topic in doc], reverse=True)\n",
    "            res.append(sum(topics[:top_n])/sum(topics))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set mallet path\n",
    "mallet_path ='mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n):\n",
    "    \n",
    "    if mod_type == 'gensim':\n",
    "        #LDA implemented with gensim\n",
    "        model = gensim.models.LdaModel(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=k,\n",
    "                                       alpha=alpha,\n",
    "                                       eta=eta,\n",
    "                                       passes=3,\n",
    "                                       iterations=100)\n",
    "    else:\n",
    "        #LDA implemented with mallet\n",
    "        model = models.wrappers.LdaMallet(mallet_path,\n",
    "                                          corpus=corpus,\n",
    "                                          id2word=id2word,\n",
    "                                          num_topics=k,\n",
    "                                          iterations=2000)\n",
    "        \n",
    "    topics = get_lda_topics(model, k)\n",
    "    flat_topic_terms = [term for topic in topics for term in topic]\n",
    "    topic_terms_not_in_ext_corpus = [[term] for term in flat_topic_terms if term not in tok2id]\n",
    "    \n",
    "    missing_topics = len(topic_terms_not_in_ext_corpus)\n",
    "    print(f'{missing_topics} number of terms not in extrinsic corpus added as separate one-term documents')\n",
    "    \n",
    "    smooth_corpus = extrinsic_data + topic_terms_not_in_ext_corpus\n",
    "    smooth_gensim_dict = corpora.Dictionary(smooth_corpus)\n",
    "    \n",
    "    #Calculate coherence\n",
    "    cv = CoherenceModel(topics=topics,\n",
    "                        texts=smooth_corpus,\n",
    "                        dictionary=smooth_gensim_dict,\n",
    "                        topn=ntw,\n",
    "                        coherence='c_v')\n",
    "    umass = CoherenceModel(topics=topics,\n",
    "                           texts=data,\n",
    "                           dictionary=id2word,\n",
    "                           topn=ntw,\n",
    "                           coherence='u_mass')\n",
    "    \n",
    "    #Calculate relative sparseness\n",
    "    res = doc_top_relative_sparseness(mod_type, model, corpus, top_n)\n",
    "\n",
    "    return model, cv.get_coherence_per_topic(), umass.get_coherence_per_topic(), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n, n_grams):\n",
    "    \n",
    "    model_results = {'Date': [],\n",
    "                     'Model': [],\n",
    "                     '#articles': [],\n",
    "                     '#topics': [],\n",
    "                     'time (s)': [],\n",
    "                     'n_grams': [],\n",
    "                     'cv_avg': [],\n",
    "                     'cv_top': [],\n",
    "                     'cv_bot': [],\n",
    "                     'umass_avg': [],\n",
    "                     'umass_top': [],\n",
    "                     'umass_bot': [],\n",
    "                     'rs_avg': [],\n",
    "                     'rs_top': [],\n",
    "                     'rs_bot': [],\n",
    "                     }\n",
    "    \n",
    "    if 1 == 1:\n",
    "        # get the coherence score for the given parameters\n",
    "        t0 = time.time()\n",
    "        model, cv, umass, res = compute_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n)\n",
    "\n",
    "        # calculate runtime\n",
    "        t1 = time.time()\n",
    "        runtime = round((t1-t0), 1)\n",
    "\n",
    "        # get current date and time\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"%d/%m/%Y %H:%M\")\n",
    "\n",
    "        # calculate cv metrics\n",
    "        m_cv = sorted(cv)\n",
    "        cv_avg = round(np.mean(m_cv), 3)\n",
    "        cv_top = get_top(m_cv)\n",
    "        cv_bot = get_bot(m_cv)\n",
    "\n",
    "        # calculate umass metrics\n",
    "        m_umass = sorted(umass)\n",
    "        umass_avg = round(np.mean(m_umass), 3)\n",
    "        umass_top = get_top(m_umass)\n",
    "        umass_bot = get_bot(m_umass)\n",
    "\n",
    "        # calculate rs metrics\n",
    "        m_rs = sorted(res)\n",
    "        rs_avg = round(np.mean(m_rs), 3)\n",
    "        rs_top = get_top(m_rs)\n",
    "        rs_bot = get_bot(m_rs)\n",
    "\n",
    "        # Save the model results\n",
    "        model_results['Date'].append(date)\n",
    "        model_results['Model'].append(mod_type)\n",
    "        model_results['#articles'].append(s)\n",
    "        model_results['#topics'].append(k)\n",
    "        model_results['time (s)'].append(runtime)\n",
    "        model_results['n_grams'].append(n_grams)\n",
    "        model_results['cv_avg'].append(cv_avg)\n",
    "        model_results['cv_top'].append(cv_top)\n",
    "        model_results['cv_bot'].append(cv_bot)\n",
    "        model_results['umass_avg'].append(umass_avg)\n",
    "        model_results['umass_top'].append(umass_top)\n",
    "        model_results['umass_bot'].append(umass_bot)\n",
    "        model_results['rs_avg'].append(rs_avg)\n",
    "        model_results['rs_top'].append(rs_top)\n",
    "        model_results['rs_bot'].append(rs_bot)\n",
    "\n",
    "    #pd.DataFrame(model_results).to_csv('lda_tuning_results_one.csv', index=False)\n",
    "    #pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False, mode='a', header=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 number of terms not in extrinsic corpus added as separate one-term documents\n"
     ]
    }
   ],
   "source": [
    "# TEST PARAMETERS\n",
    "\n",
    "DATASET_TYPE = 'BN'\n",
    "DATASET_SIZE = '10000'\n",
    "DATASET_INDEX = '1'\n",
    "\n",
    "# Load pickles:\n",
    "c1 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_1.pkl', 'rb'))\n",
    "c2 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_2.pkl', 'rb'))\n",
    "c3 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_3.pkl', 'rb'))\n",
    "c4 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_4.pkl', 'rb'))\n",
    "c5 = pickle.load(open(f'pickles/efselab_{DATASET_TYPE}_{DATASET_SIZE}_5.pkl', 'rb'))\n",
    "extrinsic_data = pickle.load( open(\"pickles/efselab_extrinsic_20000.pkl\",\"rb\"))\n",
    "data = c1 + c2 + c3 + c4 + c5\n",
    "\n",
    "\n",
    "# Use n_grams or not\n",
    "n_grams = False\n",
    "\n",
    "\n",
    "# Use NNGRAM is true, apply on data and extrinsic data\n",
    "if (n_grams is True):\n",
    "    NE_GRAMS_FILE = f'ngrams_per_dataset/ne_ngrams_{DATASET_TYPE}_{DATASET_SIZE}_{DATASET_INDEX}.pkl'\n",
    "    ne_ngrams = pickle.load(open(NE_GRAMS_FILE, 'rb'))\n",
    "    gold_ngrams = get_gold_ngrams()\n",
    "\n",
    "    # Optimized pipeline for applying ne+gold ngrams to a corpus (with ne and gold pickles)\n",
    "    phraser = build_ne_gold_phraser(ne_ngrams, gold_ngrams)\n",
    "    data = apply_ngrams(data, phraser)\n",
    "    \n",
    "    # ngram on extrinsic\n",
    "    extrinsic_data = apply_ngrams(extrinsic_data, phraser)\n",
    "    \n",
    "    \n",
    "# Format Gensim components for data\n",
    "s = len(data)\n",
    "id2word = corpora.Dictionary(data)\n",
    "id2word.filter_extremes(no_below=2)\n",
    "corpus = [id2word.doc2bow(text) for text in data]\n",
    "\n",
    "# Format Gensim components for extrisnic data\n",
    "extrinsic_id2word = corpora.Dictionary(extrinsic_data)\n",
    "extrinsic_corpus = [extrinsic_id2word.doc2bow(text) for text in extrinsic_data]\n",
    "\n",
    "# Format Gensim components for Coherence metrics\n",
    "ext_gensim_dict = corpora.Dictionary(extrinsic_data)\n",
    "tok2id = ext_gensim_dict.token2id\n",
    "\n",
    "# Model type, mallet och gensim\n",
    "mod_type = 'mallet'\n",
    "\n",
    "# Number of topics\n",
    "k = 40\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = 'auto' # Dirichlet hyperparameter alpha: Document-Topic Density\n",
    "\n",
    "# Beta parameter\n",
    "eta = 'auto' # Dirichlet hyperparameter beta: Word-Topic Density\n",
    "\n",
    "# Number of topwords used to compute coherence\n",
    "ntw = 10\n",
    "\n",
    "# Number of topic used for calculation of matrix spareness\n",
    "top_n = 3\n",
    "\n",
    "model = print_coherence_values(mod_type, corpus, id2word, data, s, k, alpha, eta, ntw, top_n, n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## EVALUATE AND ISNPECT TOPICS, NEEDS THE PARAMETER MODEL ##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod_type' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-470cb2171426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mmod_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gensim'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdoc_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msorted_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mod_type' is not defined"
     ]
    }
   ],
   "source": [
    "if mod_type == 'gensim':\n",
    "    doc_topics = model.get_document_topics(corpus, per_word_topics=False, minimum_probability=0.0)\n",
    "    \n",
    "    for k, num in enumerate(doc_topics):\n",
    "        sorted_topics = sorted(num, key=lambda tup: tup[1], reverse=True)[:3]\n",
    "        print(f'Doc{k}: ', sorted_topics)\n",
    "        \n",
    "else:\n",
    "    fname = model.fdoctopics()\n",
    "    doc_topics = model.read_doctopics(fname, eps=0, renorm=True)\n",
    "    \n",
    "    for k, num in enumerate(doc_topics):\n",
    "        sorted_topics = sorted(num, key=lambda tup: tup[1], reverse=True)[:3]\n",
    "        print(f'Doc{k}: ', sorted_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T#00</th>\n",
       "      <th>T#01</th>\n",
       "      <th>T#02</th>\n",
       "      <th>T#03</th>\n",
       "      <th>T#04</th>\n",
       "      <th>T#05</th>\n",
       "      <th>T#06</th>\n",
       "      <th>T#07</th>\n",
       "      <th>T#08</th>\n",
       "      <th>T#09</th>\n",
       "      <th>...</th>\n",
       "      <th>T#30</th>\n",
       "      <th>T#31</th>\n",
       "      <th>T#32</th>\n",
       "      <th>T#33</th>\n",
       "      <th>T#34</th>\n",
       "      <th>T#35</th>\n",
       "      <th>T#36</th>\n",
       "      <th>T#37</th>\n",
       "      <th>T#38</th>\n",
       "      <th>T#39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>krona</td>\n",
       "      <td>familj</td>\n",
       "      <td>barn</td>\n",
       "      <td>vatten</td>\n",
       "      <td>match</td>\n",
       "      <td>företag</td>\n",
       "      <td>myndighet</td>\n",
       "      <td>tidning</td>\n",
       "      <td>byrå</td>\n",
       "      <td>bild</td>\n",
       "      <td>...</td>\n",
       "      <td>mat</td>\n",
       "      <td>aktie</td>\n",
       "      <td>polis</td>\n",
       "      <td>mål</td>\n",
       "      <td>malmö</td>\n",
       "      <td>fråga</td>\n",
       "      <td>stockholm</td>\n",
       "      <td>sverige</td>\n",
       "      <td>studie</td>\n",
       "      <td>kommun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>miljon</td>\n",
       "      <td>liv</td>\n",
       "      <td>skola</td>\n",
       "      <td>skog</td>\n",
       "      <td>lag</td>\n",
       "      <td>kund</td>\n",
       "      <td>utredning</td>\n",
       "      <td>media</td>\n",
       "      <td>kampanj</td>\n",
       "      <td>tal</td>\n",
       "      <td>...</td>\n",
       "      <td>restaurang</td>\n",
       "      <td>bolag</td>\n",
       "      <td>brott</td>\n",
       "      <td>utsläpp</td>\n",
       "      <td>johan</td>\n",
       "      <td>problem</td>\n",
       "      <td>göteborg</td>\n",
       "      <td>land</td>\n",
       "      <td>forskare</td>\n",
       "      <td>förslag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peng</td>\n",
       "      <td>mamma</td>\n",
       "      <td>elev</td>\n",
       "      <td>plan</td>\n",
       "      <td>säsong</td>\n",
       "      <td>produkt</td>\n",
       "      <td>information</td>\n",
       "      <td>bonnier</td>\n",
       "      <td>kommunikation</td>\n",
       "      <td>kyrka</td>\n",
       "      <td>...</td>\n",
       "      <td>jul</td>\n",
       "      <td>bank</td>\n",
       "      <td>kvinna</td>\n",
       "      <td>företag</td>\n",
       "      <td>andersson</td>\n",
       "      <td>samhälle</td>\n",
       "      <td>peter</td>\n",
       "      <td>antal</td>\n",
       "      <td>risk</td>\n",
       "      <td>verksamhet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miljard</td>\n",
       "      <td>vän</td>\n",
       "      <td>förälder</td>\n",
       "      <td>område</td>\n",
       "      <td>mål</td>\n",
       "      <td>butik</td>\n",
       "      <td>fråga</td>\n",
       "      <td>expressen</td>\n",
       "      <td>kund</td>\n",
       "      <td>utställning</td>\n",
       "      <td>...</td>\n",
       "      <td>kött</td>\n",
       "      <td>dollar</td>\n",
       "      <td>händelse</td>\n",
       "      <td>rapport</td>\n",
       "      <td>anders</td>\n",
       "      <td>exempel</td>\n",
       "      <td>pris</td>\n",
       "      <td>värld</td>\n",
       "      <td>sjukdom</td>\n",
       "      <td>ordförande</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resultat</td>\n",
       "      <td>pappa</td>\n",
       "      <td>ungdom</td>\n",
       "      <td>grad</td>\n",
       "      <td>spelare</td>\n",
       "      <td>marknad</td>\n",
       "      <td>regel</td>\n",
       "      <td>journalist</td>\n",
       "      <td>varumärke</td>\n",
       "      <td>museum</td>\n",
       "      <td>...</td>\n",
       "      <td>vin</td>\n",
       "      <td>kvartal</td>\n",
       "      <td>tingsrätt</td>\n",
       "      <td>hållbarhet</td>\n",
       "      <td>nilsson</td>\n",
       "      <td>svar</td>\n",
       "      <td>lars</td>\n",
       "      <td>svensk</td>\n",
       "      <td>patient</td>\n",
       "      <td>budget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bolag</td>\n",
       "      <td>barn</td>\n",
       "      <td>utbildning</td>\n",
       "      <td>hav</td>\n",
       "      <td>klubb</td>\n",
       "      <td>varumärke</td>\n",
       "      <td>uppgift</td>\n",
       "      <td>aftonbladet</td>\n",
       "      <td>resumé</td>\n",
       "      <td>verk</td>\n",
       "      <td>...</td>\n",
       "      <td>smak</td>\n",
       "      <td>miljard</td>\n",
       "      <td>åklagare</td>\n",
       "      <td>miljö</td>\n",
       "      <td>mikael</td>\n",
       "      <td>ord</td>\n",
       "      <td>björn</td>\n",
       "      <td>siffra</td>\n",
       "      <td>resultat</td>\n",
       "      <td>politiker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vinst</td>\n",
       "      <td>hand</td>\n",
       "      <td>lärare</td>\n",
       "      <td>träd</td>\n",
       "      <td>poäng</td>\n",
       "      <td>bolag</td>\n",
       "      <td>lag</td>\n",
       "      <td>metro</td>\n",
       "      <td>director</td>\n",
       "      <td>konstnär</td>\n",
       "      <td>...</td>\n",
       "      <td>ställe</td>\n",
       "      <td>tillväxt</td>\n",
       "      <td>mord</td>\n",
       "      <td>klimat</td>\n",
       "      <td>jonas</td>\n",
       "      <td>ställe</td>\n",
       "      <td>lista</td>\n",
       "      <td>norge</td>\n",
       "      <td>behandling</td>\n",
       "      <td>arbete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kostnad</td>\n",
       "      <td>son</td>\n",
       "      <td>student</td>\n",
       "      <td>väder</td>\n",
       "      <td>tränare</td>\n",
       "      <td>konsument</td>\n",
       "      <td>krav</td>\n",
       "      <td>vd</td>\n",
       "      <td>samarbete</td>\n",
       "      <td>konst</td>\n",
       "      <td>...</td>\n",
       "      <td>tips</td>\n",
       "      <td>börs</td>\n",
       "      <td>fängelse</td>\n",
       "      <td>värld</td>\n",
       "      <td>larsson</td>\n",
       "      <td>debatt</td>\n",
       "      <td>stad</td>\n",
       "      <td>danmark</td>\n",
       "      <td>forskning</td>\n",
       "      <td>behov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>siffra</td>\n",
       "      <td>dotter</td>\n",
       "      <td>förskola</td>\n",
       "      <td>mark</td>\n",
       "      <td>vetlanda</td>\n",
       "      <td>bransch</td>\n",
       "      <td>åtgärd</td>\n",
       "      <td>svt</td>\n",
       "      <td>reklam</td>\n",
       "      <td>historia</td>\n",
       "      <td>...</td>\n",
       "      <td>kök</td>\n",
       "      <td>swedbank</td>\n",
       "      <td>plats</td>\n",
       "      <td>kommentar</td>\n",
       "      <td>andreas</td>\n",
       "      <td>folk</td>\n",
       "      <td>karin</td>\n",
       "      <td>finland</td>\n",
       "      <td>läkemedel</td>\n",
       "      <td>fråga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ökning</td>\n",
       "      <td>par</td>\n",
       "      <td>pojke</td>\n",
       "      <td>flygplats</td>\n",
       "      <td>division</td>\n",
       "      <td>marknadsföring</td>\n",
       "      <td>problem</td>\n",
       "      <td>läsare</td>\n",
       "      <td>idé</td>\n",
       "      <td>sten</td>\n",
       "      <td>...</td>\n",
       "      <td>öl</td>\n",
       "      <td>marknad</td>\n",
       "      <td>utredning</td>\n",
       "      <td>plast</td>\n",
       "      <td>persson</td>\n",
       "      <td>tal</td>\n",
       "      <td>mattias</td>\n",
       "      <td>europa</td>\n",
       "      <td>kvinna</td>\n",
       "      <td>peng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       T#00    T#01        T#02       T#03      T#04            T#05  \\\n",
       "0     krona  familj        barn     vatten     match         företag   \n",
       "1    miljon     liv       skola       skog       lag            kund   \n",
       "2      peng   mamma        elev       plan    säsong         produkt   \n",
       "3   miljard     vän    förälder     område       mål           butik   \n",
       "4  resultat   pappa      ungdom       grad   spelare         marknad   \n",
       "5     bolag    barn  utbildning        hav     klubb       varumärke   \n",
       "6     vinst    hand      lärare       träd     poäng           bolag   \n",
       "7   kostnad     son     student      väder   tränare       konsument   \n",
       "8    siffra  dotter    förskola       mark  vetlanda         bransch   \n",
       "9    ökning     par       pojke  flygplats  division  marknadsföring   \n",
       "\n",
       "          T#06         T#07           T#08         T#09  ...        T#30  \\\n",
       "0    myndighet      tidning           byrå         bild  ...         mat   \n",
       "1    utredning        media        kampanj          tal  ...  restaurang   \n",
       "2  information      bonnier  kommunikation        kyrka  ...         jul   \n",
       "3        fråga    expressen           kund  utställning  ...        kött   \n",
       "4        regel   journalist      varumärke       museum  ...         vin   \n",
       "5      uppgift  aftonbladet         resumé         verk  ...        smak   \n",
       "6          lag        metro       director     konstnär  ...      ställe   \n",
       "7         krav           vd      samarbete        konst  ...        tips   \n",
       "8       åtgärd          svt         reklam     historia  ...         kök   \n",
       "9      problem       läsare            idé         sten  ...          öl   \n",
       "\n",
       "       T#31       T#32        T#33       T#34      T#35       T#36     T#37  \\\n",
       "0     aktie      polis         mål      malmö     fråga  stockholm  sverige   \n",
       "1     bolag      brott     utsläpp      johan   problem   göteborg     land   \n",
       "2      bank     kvinna     företag  andersson  samhälle      peter    antal   \n",
       "3    dollar   händelse     rapport     anders   exempel       pris    värld   \n",
       "4   kvartal  tingsrätt  hållbarhet    nilsson      svar       lars   svensk   \n",
       "5   miljard   åklagare       miljö     mikael       ord      björn   siffra   \n",
       "6  tillväxt       mord      klimat      jonas    ställe      lista    norge   \n",
       "7      börs   fängelse       värld    larsson    debatt       stad  danmark   \n",
       "8  swedbank      plats   kommentar    andreas      folk      karin  finland   \n",
       "9   marknad  utredning       plast    persson       tal    mattias   europa   \n",
       "\n",
       "         T#38        T#39  \n",
       "0      studie      kommun  \n",
       "1    forskare     förslag  \n",
       "2        risk  verksamhet  \n",
       "3     sjukdom  ordförande  \n",
       "4     patient      budget  \n",
       "5    resultat   politiker  \n",
       "6  behandling      arbete  \n",
       "7   forskning       behov  \n",
       "8   läkemedel       fråga  \n",
       "9      kvinna        peng  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print topics with N top words\n",
    "num_topics = 40\n",
    "\n",
    "def print_topics_words(model, num_topics):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 10);\n",
    "        word_dict['T#' + '{:02d}'.format(i)] = [i[0] for i in words];\n",
    "        df = pd.DataFrame(word_dict);\n",
    "    return df\n",
    "\n",
    "topic_df = print_topics_words(model, num_topics)\n",
    "topic_df.to_csv('BN_40_TOPICS.csv')\n",
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "import gensim    \n",
    "#model_plot = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model)\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, dictionary=id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TYPE = 'random'\n",
    "DATASET_SIZE = '4000'\n",
    "DATASET_INDEX = '3'\n",
    "\n",
    "other_texts = pickle.load(open(f'efselab_mod/pickles/efselab_parsed_{DATASET_TYPE}_{DATASET_SIZE}_{DATASET_INDEX}.pkl', 'rb'))\n",
    "\n",
    "new_article = other_texts[10]\n",
    "\n",
    "id2word = corpora.Dictionary(other_texts)\n",
    "other_corpus = [id2word.doc2bow(text) for text in other_texts]\n",
    "\n",
    "new_article_corpus = other_corpus[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_2 = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(model)\n",
    "#model.update(other_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_article_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model[new_article_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
